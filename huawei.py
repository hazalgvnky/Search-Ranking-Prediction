#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd


# In[2]:


mm = pd.read_csv('/Users/macbookretina/Desktop/submission.csv')
mm


# In[3]:


import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import categorical_crossentropy
from sklearn import preprocessing 
from tensorflow import metrics


# In[10]:


model = Sequential([
        Dense(units=8,input_shape=(256,), activation='relu'),
        Dense(units=16,activation='relu'),
        Dense(units=32,activation='relu'),
        Dense(units=5,activation='relu'),
        Dense(units=5,activation='softmax')
    ]
    )


# In[11]:


#'categorical_crossentropy'
model.compile(loss='categorical_hinge', optimizer= 'Adam',metrics=['categorical_accuracy'])


# In[6]:


#200,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363]
df = pd.read_csv(
            '/Users/macbookretina/Desktop/train_dataset.csv',header=None,sep='\t',
            usecols=[0,6,39,51,52,53,54,55,56,57,58,60,61,79,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363]
)


# In[7]:


labels = df.iloc[:,[0]]
labels = np.array(labels) 
    
        
features = df.iloc[:, 1:]
features = np.array(features)


# In[8]:


scalar = preprocessing.MinMaxScaler()
scaled_feats = scalar.fit_transform(features)
    
features = None


# In[12]:


model.fit(scaled_feats,labels,shuffle=True,validation_split=0.15,batch_size=32,epochs=15,verbose=2)


# In[13]:


test_df = pd.read_csv(
            '/Users/macbookretina/Desktop/test_dataset_B.csv',header=None,sep='\t',
            usecols=[6,39,51,52,53,54,55,56,57,58,60,61,79,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363]
)


# In[14]:


test_df = np.array(test_df)


# In[15]:


scalar = preprocessing.MinMaxScaler()
scaled_test_df = scalar.fit_transform(test_df)


# In[16]:


predicted = model.predict(scaled_test_df)


# In[17]:


mm['predict_label']=predicted


# In[18]:


mm


# In[19]:


path ="/Users/macbookretina/Desktop/submission.csv"
mm.to_csv(path,index = False)

